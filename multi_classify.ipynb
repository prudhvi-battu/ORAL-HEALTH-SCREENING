{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.8.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (1.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "Keras Version: 3.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Keras Version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking class distribution...\n",
      "Before Balancing: {'Calculus': 613, 'Caries': 618, 'Gingivitis': 619, 'healthy': 611}\n",
      "‚úÖ After Balancing: {'Calculus': 613, 'Caries': 618, 'Gingivitis': 619, 'healthy': 611}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = \"C:\\\\Users\\\\megha\\\\OneDrive\\\\Desktop\\\\Major Project\\\\Dataset\\\\multi_dataset\"  # Update with your dataset directory path\n",
    "TARGET_SIZE = 600  # Minimum number of images per class\n",
    "\n",
    "# Function to check class distribution\n",
    "def check_class_distribution(dataset_path):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_dir):  # Ensure it's a folder\n",
    "            num_images = len(os.listdir(class_dir))\n",
    "            class_counts[class_name] = num_images\n",
    "    return class_counts\n",
    "\n",
    "# Function to apply oversampling (copying images)\n",
    "def oversample_class(class_dir, target_size):\n",
    "    current_images = os.listdir(class_dir)\n",
    "    current_count = len(current_images)\n",
    "\n",
    "    while current_count < target_size:\n",
    "        file = random.choice(current_images)  # Pick a random image\n",
    "        new_file = f\"copy_{current_count}_{file}\"\n",
    "        shutil.copy(os.path.join(class_dir, file), os.path.join(class_dir, new_file))\n",
    "        current_count += 1\n",
    "    print(f\"‚úÖ Oversampled {os.path.basename(class_dir)} to {target_size} images\")\n",
    "\n",
    "# Function to apply data augmentation\n",
    "def augment_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize to match model input size\n",
    "\n",
    "    # Apply random augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    img = np.expand_dims(img, axis=0)  # Expand dimension for augmentation\n",
    "    it = datagen.flow(img, batch_size=1)\n",
    "\n",
    "    augmented_img = next(it)[0].astype(np.uint8)  # Get augmented image\n",
    "    return augmented_img\n",
    "\n",
    "# Function to balance dataset using oversampling and augmentation\n",
    "def balance_dataset(dataset_path, target_size=TARGET_SIZE):\n",
    "    class_counts = check_class_distribution(dataset_path)\n",
    "\n",
    "    for class_name, num_images in class_counts.items():\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "\n",
    "        if num_images < target_size:\n",
    "            print(f\"‚ö†Ô∏è Class {class_name} has only {num_images} images. Balancing...\")\n",
    "            \n",
    "            while num_images < target_size:\n",
    "                file = random.choice(os.listdir(class_dir))\n",
    "                img_path = os.path.join(class_dir, file)\n",
    "\n",
    "                if num_images % 2 == 0:\n",
    "                    # Oversampling (Copy existing images)\n",
    "                    new_file = f\"copy_{num_images}_{file}\"\n",
    "                    shutil.copy(img_path, os.path.join(class_dir, new_file))\n",
    "                else:\n",
    "                    # Data Augmentation (Generate new variations)\n",
    "                    augmented_img = augment_image(img_path)\n",
    "                    new_file = f\"aug_{num_images}.jpg\"\n",
    "                    cv2.imwrite(os.path.join(class_dir, new_file), augmented_img)\n",
    "\n",
    "                num_images += 1\n",
    "\n",
    "            print(f\"‚úÖ {class_name} balanced to {target_size} images.\")\n",
    "\n",
    "# Run the balancing process\n",
    "print(\"üîç Checking class distribution...\")\n",
    "before_counts = check_class_distribution(dataset_path)\n",
    "print(\"Before Balancing:\", before_counts)\n",
    "\n",
    "balance_dataset(dataset_path)\n",
    "\n",
    "after_counts = check_class_distribution(dataset_path)\n",
    "print(\"‚úÖ After Balancing:\", after_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.18.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.8.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.53.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: rich in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\megha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow numpy matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1971 images belonging to 4 classes.\n",
      "Found 490 images belonging to 4 classes.\n",
      "Class Indices: {'Calculus': 0, 'Caries': 1, 'Gingivitis': 2, 'healthy': 3}\n"
     ]
    }
   ],
   "source": [
    "# Define dataset path\n",
    "dataset_path = \"C:\\\\Users\\\\megha\\\\OneDrive\\\\Desktop\\\\Major Project\\\\Dataset\\\\multi_dataset\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Define Image Augmentation & Normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2  # 80% Training, 20% Validation\n",
    ")\n",
    "\n",
    "# Load Training Data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Load Validation Data\n",
    "val_data = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Get Class Labels\n",
    "print(\"Class Indices:\", train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.5102 - loss: 1.1981 - val_accuracy: 0.7408 - val_loss: 0.6440\n",
      "Epoch 2/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 671ms/step - accuracy: 0.7590 - loss: 0.5825 - val_accuracy: 0.6959 - val_loss: 0.6667\n",
      "Epoch 3/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 753ms/step - accuracy: 0.8109 - loss: 0.4953 - val_accuracy: 0.7449 - val_loss: 0.5840\n",
      "Epoch 4/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 665ms/step - accuracy: 0.8245 - loss: 0.4067 - val_accuracy: 0.8122 - val_loss: 0.4516\n",
      "Epoch 5/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 663ms/step - accuracy: 0.8567 - loss: 0.3515 - val_accuracy: 0.8102 - val_loss: 0.4392\n",
      "Epoch 6/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 552ms/step - accuracy: 0.8863 - loss: 0.2959 - val_accuracy: 0.8000 - val_loss: 0.4799\n",
      "Epoch 7/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - accuracy: 0.8974 - loss: 0.2861 - val_accuracy: 0.8306 - val_loss: 0.4061\n",
      "Epoch 8/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 537ms/step - accuracy: 0.8939 - loss: 0.2640 - val_accuracy: 0.8204 - val_loss: 0.4049\n",
      "Epoch 9/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - accuracy: 0.8969 - loss: 0.2380 - val_accuracy: 0.8367 - val_loss: 0.3892\n",
      "Epoch 10/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 532ms/step - accuracy: 0.8953 - loss: 0.2436 - val_accuracy: 0.8224 - val_loss: 0.4133\n",
      "Epoch 11/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 533ms/step - accuracy: 0.9110 - loss: 0.2094 - val_accuracy: 0.8367 - val_loss: 0.3996\n",
      "Epoch 12/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 540ms/step - accuracy: 0.9183 - loss: 0.1979 - val_accuracy: 0.8286 - val_loss: 0.4086\n",
      "Epoch 13/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - accuracy: 0.9238 - loss: 0.1993 - val_accuracy: 0.8184 - val_loss: 0.4224\n",
      "Epoch 14/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 529ms/step - accuracy: 0.9329 - loss: 0.1834 - val_accuracy: 0.8184 - val_loss: 0.4455\n",
      "Epoch 15/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 524ms/step - accuracy: 0.9262 - loss: 0.1664 - val_accuracy: 0.8408 - val_loss: 0.4463\n",
      "Epoch 16/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 524ms/step - accuracy: 0.9285 - loss: 0.1855 - val_accuracy: 0.8224 - val_loss: 0.4326\n",
      "Epoch 17/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 525ms/step - accuracy: 0.9347 - loss: 0.1627 - val_accuracy: 0.8449 - val_loss: 0.4113\n",
      "Epoch 18/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 523ms/step - accuracy: 0.9289 - loss: 0.1824 - val_accuracy: 0.8020 - val_loss: 0.4791\n",
      "Epoch 19/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - accuracy: 0.9247 - loss: 0.1873 - val_accuracy: 0.8429 - val_loss: 0.4097\n",
      "Epoch 20/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - accuracy: 0.9300 - loss: 0.1721 - val_accuracy: 0.8327 - val_loss: 0.3880\n",
      "Epoch 21/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 539ms/step - accuracy: 0.9357 - loss: 0.1599 - val_accuracy: 0.8429 - val_loss: 0.4630\n",
      "Epoch 22/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - accuracy: 0.9398 - loss: 0.1486 - val_accuracy: 0.8449 - val_loss: 0.3941\n",
      "Epoch 23/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 527ms/step - accuracy: 0.9398 - loss: 0.1458 - val_accuracy: 0.8429 - val_loss: 0.4247\n",
      "Epoch 24/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 530ms/step - accuracy: 0.9377 - loss: 0.1536 - val_accuracy: 0.8327 - val_loss: 0.4902\n",
      "Epoch 25/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - accuracy: 0.9479 - loss: 0.1483 - val_accuracy: 0.8265 - val_loss: 0.4245\n",
      "Epoch 26/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - accuracy: 0.9361 - loss: 0.1501 - val_accuracy: 0.8367 - val_loss: 0.4271\n",
      "Epoch 27/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - accuracy: 0.9379 - loss: 0.1371 - val_accuracy: 0.8408 - val_loss: 0.4579\n",
      "Epoch 28/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 528ms/step - accuracy: 0.9352 - loss: 0.1413 - val_accuracy: 0.8163 - val_loss: 0.4556\n",
      "Epoch 29/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 540ms/step - accuracy: 0.9363 - loss: 0.1480 - val_accuracy: 0.8184 - val_loss: 0.4763\n",
      "Epoch 30/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 541ms/step - accuracy: 0.9380 - loss: 0.1383 - val_accuracy: 0.8306 - val_loss: 0.5013\n",
      "Epoch 31/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - accuracy: 0.9386 - loss: 0.1358 - val_accuracy: 0.8224 - val_loss: 0.5009\n",
      "Epoch 32/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - accuracy: 0.9373 - loss: 0.1404 - val_accuracy: 0.8347 - val_loss: 0.4921\n",
      "Epoch 33/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 534ms/step - accuracy: 0.9379 - loss: 0.1457 - val_accuracy: 0.8286 - val_loss: 0.4932\n",
      "Epoch 34/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 537ms/step - accuracy: 0.9443 - loss: 0.1320 - val_accuracy: 0.8286 - val_loss: 0.4769\n",
      "Epoch 35/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - accuracy: 0.9307 - loss: 0.1411 - val_accuracy: 0.8265 - val_loss: 0.4876\n",
      "Epoch 36/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 536ms/step - accuracy: 0.9433 - loss: 0.1368 - val_accuracy: 0.8306 - val_loss: 0.5158\n",
      "Epoch 37/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 542ms/step - accuracy: 0.9514 - loss: 0.1146 - val_accuracy: 0.8388 - val_loss: 0.5026\n",
      "Epoch 38/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 552ms/step - accuracy: 0.9224 - loss: 0.1514 - val_accuracy: 0.8306 - val_loss: 0.4996\n",
      "Epoch 39/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 543ms/step - accuracy: 0.9339 - loss: 0.1395 - val_accuracy: 0.8224 - val_loss: 0.5705\n",
      "Epoch 40/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 538ms/step - accuracy: 0.9523 - loss: 0.1086 - val_accuracy: 0.8224 - val_loss: 0.4980\n",
      "Epoch 41/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 540ms/step - accuracy: 0.9571 - loss: 0.1047 - val_accuracy: 0.8347 - val_loss: 0.4380\n",
      "Epoch 42/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 546ms/step - accuracy: 0.9429 - loss: 0.1336 - val_accuracy: 0.8265 - val_loss: 0.5256\n",
      "Epoch 43/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 539ms/step - accuracy: 0.9332 - loss: 0.1423 - val_accuracy: 0.8184 - val_loss: 0.5332\n",
      "Epoch 44/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 537ms/step - accuracy: 0.9379 - loss: 0.1309 - val_accuracy: 0.8429 - val_loss: 0.5002\n",
      "Epoch 45/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 539ms/step - accuracy: 0.9450 - loss: 0.1216 - val_accuracy: 0.8224 - val_loss: 0.4972\n",
      "Epoch 46/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 535ms/step - accuracy: 0.9524 - loss: 0.1123 - val_accuracy: 0.8327 - val_loss: 0.5017\n",
      "Epoch 47/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 545ms/step - accuracy: 0.9440 - loss: 0.1295 - val_accuracy: 0.8245 - val_loss: 0.4949\n",
      "Epoch 48/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 677ms/step - accuracy: 0.9493 - loss: 0.1140 - val_accuracy: 0.8061 - val_loss: 0.5896\n",
      "Epoch 49/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 542ms/step - accuracy: 0.9415 - loss: 0.1265 - val_accuracy: 0.8265 - val_loss: 0.5481\n",
      "Epoch 50/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 539ms/step - accuracy: 0.9447 - loss: 0.1170 - val_accuracy: 0.8184 - val_loss: 0.5741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained MobileNetV2 Model\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "base_model.trainable = False  # Freeze Pretrained Layers\n",
    "\n",
    "# Build MobileNetV2 Model\n",
    "mobilenet_model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation=\"softmax\")  # 4 classes: Healthy, Caries, Calculus, Hypodontia\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "mobilenet_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train MobileNetV2 Model\n",
    "EPOCHS = 50\n",
    "mobilenet_history = mobilenet_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "# Save Model\n",
    "mobilenet_model.save(\"mobilenet_dental_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 441ms/step - accuracy: 0.8192 - loss: 0.4681\n",
      "MobileNetV2 - Validation Accuracy: 0.8184\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MobileNetV2\n",
    "mobilenet_loss, mobilenet_accuracy = mobilenet_model.evaluate(val_data)\n",
    "print(f\"MobileNetV2 - Validation Accuracy: {mobilenet_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted Class: Calculus (Confidence: 0.9987)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load Model\n",
    "model = tf.keras.models.load_model(\"mobilenet_dental_model.h5\")\n",
    "\n",
    "# Define Class Labels\n",
    "class_labels = [\"Calculus\", \"Caries\", \"Gingivitis\",\"Healthy\"]\n",
    "\n",
    "# Function to Predict on New Images\n",
    "def predict_image(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img) / 255.0  # Normalize\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    confidence_score = np.max(prediction)\n",
    "\n",
    "    print(f\"Predicted Class: {predicted_class} (Confidence: {confidence_score:.4f})\")\n",
    "\n",
    "# Predict on a Sample Image\n",
    "img_path = \"C:\\\\Users\\\\megha\\\\OneDrive\\\\Desktop\\\\Major Project\\\\Dataset\\\\test\\\\ca1.jpg\"\n",
    "predict_image(img_path, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
